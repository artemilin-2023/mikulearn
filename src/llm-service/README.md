# LLM-сервис для генерации тестов

Микросервис на Python для обработки задач из RabbitMQ, генерации тестов с помощью LLM и отправки результатов обратно.

## Обзор

Сервис выполняет следующие функции:
1. Подключается к RabbitMQ и настраивает очереди для приема задач и отправки результатов
2. Слушает очередь задач и обрабатывает входящие сообщения
3. При получении задачи отправляет статус "В обработке"
4. Генерирует тест на основе описания и имени файла
5. Отправляет сгенерированный тест и обновление статуса "Успешно" или "Ошибка"

## Структура проекта

- `main.py` - основной файл с логикой сервиса
- `requirements.txt` - зависимости проекта
- `Dockerfile` - конфигурация для Docker-контейнера

## Запуск

### Локальный запуск

```bash
# Установить зависимости
pip install -r requirements.txt

# Запустить сервис
python main.py
```

### Запуск через Docker

```bash
# Собрать образ
docker build -t llm-service .

# Запустить контейнер
docker run --network=<network_name> llm-service
```

## Переменные окружения

- `RABBITMQ_URL` - URL для подключения к RabbitMQ (по умолчанию: "amqp://rmuser:rmpassword@rabbitmq:5672")
- `TASK_QUEUE_NAME` - имя очереди для задач (по умолчанию: "task_queue")
- `RESPONSE_QUEUE_NAME` - имя очереди для ответов (по умолчанию: "response_queue")
- `TASK_ROUTING_KEY` - ключ маршрутизации для задач (по умолчанию: "llm.tasks")
- `RESPONSE_ROUTING_KEY` - ключ маршрутизации для ответов (по умолчанию: "llm.response")
- `EXCHANGE_NAME` - имя exchange (по умолчанию: "llm.services") 